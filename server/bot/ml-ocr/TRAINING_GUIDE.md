
# Guide d'EntraÃ®nement ML OCR

## ğŸ“‹ PrÃ©requis

Avant de commencer l'entraÃ®nement, assurez-vous d'avoir :

1. **DonnÃ©es d'entraÃ®nement** : Minimum 500 exemples par catÃ©gorie (rank, suit, digit)
2. **Structure de rÃ©pertoires** : CrÃ©Ã©e automatiquement par le script
3. **Labels dÃ©finis** : Voir `datasets/labels.json`

## ğŸš€ DÃ©marrage Rapide

### Ã‰tape 1 : Validation du Dataset

```bash
npm run validate:dataset
```

Ce script vÃ©rifie :
- âœ… IntÃ©gritÃ© des images
- âœ… ValiditÃ© des labels
- âœ… Doublons
- âœ… Confiance des annotations

### Ã‰tape 2 : Lancement de l'EntraÃ®nement

```bash
npm run train:ml
```

Le pipeline va :
1. VÃ©rifier les donnÃ©es disponibles
2. GÃ©nÃ©rer des donnÃ©es synthÃ©tiques si nÃ©cessaire (minimum 500 par catÃ©gorie)
3. EntraÃ®ner les 3 classificateurs (rank, suit, digit)
4. Sauvegarder les poids dans `server/bot/ml-ocr/weights/`
5. GÃ©nÃ©rer un rapport d'entraÃ®nement

## ğŸ“Š Structure des Datasets

```
server/bot/ml-ocr/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ raw/              # Captures brutes
â”‚   â”œâ”€â”€ annotated/        # Images + JSON annotations
â”‚   â”œâ”€â”€ preprocessed/     # Images prÃ©traitÃ©es
â”‚   â””â”€â”€ splits/           # Train/Val/Test (80/10/10)
â”œâ”€â”€ training-data/
â”‚   â”œâ”€â”€ images/           # Images d'exemples
â”‚   â””â”€â”€ samples.json      # Index des samples
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ rank-weights.json
â”‚   â”œâ”€â”€ suit-weights.json
â”‚   â””â”€â”€ digit-weights.json
â””â”€â”€ logs/
    â””â”€â”€ training-report-*.json
```

## ğŸ¯ Configuration de l'EntraÃ®nement

Fichier : `datasets/labels.json`

```json
{
  "training_defaults": {
    "batch_size": 32,
    "epochs": 50,
    "learning_rate": 0.001,
    "validation_split": 0.2,
    "early_stop_patience": 5
  }
}
```

### Personnalisation

Dans `script/train-ml-models.ts`, modifiez :

```typescript
config: {
  learningRate: 0.001,      // Taux d'apprentissage
  batchSize: 32,            // Taille des batchs
  epochs: 50,               // Nombre d'epochs max
  validationSplit: 0.2,     // 20% pour validation
  augmentation: true,       // Activer augmentation
  earlyStopPatience: 5      // ArrÃªt si pas d'amÃ©lioration
}
```

## ğŸ“ˆ Augmentation de DonnÃ©es

L'augmentation est appliquÃ©e automatiquement :

### Rank (Rangs de cartes)
- Rotation : Â±5Â°
- LuminositÃ© : 80-120%
- Contraste : 90-110%
- Bruit : 5%

### Suit (Couleurs)
- Rotation : Â±10Â°
- LuminositÃ© : 70-130%
- Contraste : 80-120%
- DÃ©calage teinte : Â±5Â°

### Digit (Chiffres)
- Rotation : Â±3Â°
- LuminositÃ© : 85-115%
- Contraste : 95-105%
- Ã‰chelle : 95-105%

## ğŸ“Š Ã‰valuation des ModÃ¨les

AprÃ¨s entraÃ®nement, consultez le rapport :

```json
{
  "results": {
    "rank": {
      "finalAccuracy": 0.95,
      "finalLoss": 0.12,
      "trainingTime": 45000
    }
  }
}
```

### Objectifs de Performance

- **Rank Classifier** : Accuracy > 95%
- **Suit Classifier** : Accuracy > 92%
- **Digit Classifier** : Accuracy > 90%

## ğŸ”§ DÃ©pannage

### PrÃ©cision Faible (<80%)

**Solutions** :
1. Collecter plus de donnÃ©es (objectif 1000+ par catÃ©gorie)
2. Augmenter epochs (essayer 100)
3. RÃ©duire learning rate (0.0005)
4. VÃ©rifier qualitÃ© des annotations

### Overfitting (Validation Loss >> Training Loss)

**Solutions** :
1. Augmenter augmentation de donnÃ©es
2. Ajouter dropout (dÃ©jÃ  Ã  0.3)
3. RÃ©duire complexitÃ© du modÃ¨le
4. Collecter plus de donnÃ©es variÃ©es

### Underfitting (Training Loss stagne)

**Solutions** :
1. Augmenter complexitÃ© du modÃ¨le
2. Augmenter epochs
3. Ajuster learning rate
4. VÃ©rifier prÃ©traitement des images

## ğŸ¨ GÃ©nÃ©ration de DonnÃ©es SynthÃ©tiques

Si vous n'avez pas assez de donnÃ©es rÃ©elles :

```typescript
import { getDataCollector } from './server/bot/ml-ocr/data-collector';

const collector = await getDataCollector();

// GÃ©nÃ©rer 500 exemples de rangs
await collector.generateSyntheticData('rank', 500);

// GÃ©nÃ©rer 500 exemples de couleurs
await collector.generateSyntheticData('suit', 500);

// GÃ©nÃ©rer 500 exemples de chiffres
await collector.generateSyntheticData('digit', 500);
```

**Note** : Les donnÃ©es synthÃ©tiques sont utiles pour dÃ©marrer, mais les donnÃ©es rÃ©elles sont toujours prÃ©fÃ©rables.

## ğŸ“ Collecte de DonnÃ©es RÃ©elles

Pour collecter automatiquement des donnÃ©es pendant le jeu :

1. Activer dans `poker-ocr-engine.ts` :
```typescript
const config = {
  collectTrainingData: true,
  // ...
};
```

2. Le systÃ¨me collecte automatiquement quand :
   - Confiance ML > 95%
   - Sauvegarde auto toutes les 100 exemples

3. VÃ©rifier les donnÃ©es collectÃ©es :
```bash
npm run validate:dataset
```

## ğŸ¯ Pipeline Complet

```bash
# 1. Valider dataset existant
npm run validate:dataset

# 2. Lancer l'entraÃ®nement (gÃ©nÃ©ration synthÃ©tique auto)
npm run train:ml

# 3. VÃ©rifier les poids gÃ©nÃ©rÃ©s
ls server/bot/ml-ocr/weights/

# 4. Tester en production
npm run dev
```

## ğŸ“Š Monitoring de l'EntraÃ®nement

Les rapports sont sauvegardÃ©s dans `server/bot/ml-ocr/logs/` :

```json
{
  "timestamp": "2025-01-01T12:00:00.000Z",
  "duration_minutes": "15.5",
  "results": {
    "rank": { "finalAccuracy": 0.95 },
    "suit": { "finalAccuracy": 0.93 },
    "digit": { "finalAccuracy": 0.91 }
  },
  "errors": []
}
```

## ğŸ”„ RÃ©-entraÃ®nement

Pour amÃ©liorer un modÃ¨le existant :

1. Collecter plus de donnÃ©es (notamment les erreurs)
2. Augmenter epochs ou learning rate
3. Relancer `npm run train:ml`
4. Les anciens poids sont Ã©crasÃ©s (faire backup si nÃ©cessaire)
